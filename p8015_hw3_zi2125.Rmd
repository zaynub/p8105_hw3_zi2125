---
title: "Homework 3"
author: "Zaynub Ibrahim"
output: github_document
---

### Problem 1

```{r}
library(tidyverse)
library(p8105.datasets)
library(patchwork)
library(ggridges)
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric code. The data set shows an order number, and how long it has been since the order was placed and also shows the item that is ordered and which aisle and department it is located in. 

How many aisles, and which are most items from? 

```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

Make a plot that shows the number of items ordered in each aisle:

```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Make a table that shows most popular items in “baking ingredients”, “dog food care”, and “packaged vegetables fruits” aisles. 

```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```


### Problem 2

Read and Tidy accel_data: 

```{r}
accel_df = read_csv(file = "./data/accel_data.csv") %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "minute",
    names_prefix = "activity.",
    values_to = "activity"
  ) %>% 
  group_by(day) %>% 
  mutate(
    minute = as.numeric(minute),
    day = as.factor(day),
    activity = as.numeric(activity),
    day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")),
    weekday_or_weekend =  if_else(day %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
  )
```

This tidy accel_df dataset contains five weeks of accelerometer data collected on a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF). It has `r nrow(accel_df)` rows and `r ncol(accel_df)` and contains variables `r names(accel_df)`. 

Now I am creating a table to show total activity variable for each day.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(aggregate_activity = sum(activity)) %>% 
  knitr::kable()
```

No apparent trends stand out just from looking at this aggregate table. However, it is interesting to note that the level of activity on the last two Saturdays was significantly lower than any of the other days. 

Next, I am creating a plot that shows the 24-hour activity time courses for each day. 

```{r}
accel_df %>% 
  ggplot(aes(x = minute, y = activity, color = factor(day))) +
  geom_line() +
  labs(
    title = "Accelerometer Activity over Time",
    x = "minute of the Day",
    y = "Activity"
  ) 
```

The graph shows that there seems to be more consistently higher levels of activity on Thursdays and Sundays. Even though Wedenesday shows the consistently lowest levels of activity, there is one Wednesday where the max level of activity was recorded. On Fridays, he tends to be more active later in the day while on Thursday and Sunday, he is more active earlier in the day.   

### Problem 3 

Load the dataset: 

```{r}
data("ny_noaa")
```

This dataset contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns and includes variables `r names(ny_noaa)`. This data contains information on weather in NY and includes snowfall and snow depth in mm, precipitation in tenths of a mm, as well as the max and min temperature in tenths of degrees C. There is a lot of missing data since each weather station can only collect information on a subset of these variables on any given day.   

Tidy the data: 

```{r}
noaa_df <- ny_noaa %>%
  separate(date, sep = "-", into = c("year", "month", "day"), convert = TRUE) %>%
  mutate( 
    prcp = prcp/10,
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin), 
    tmax = tmax/10,
    tmin = tmin/10)

ny_noaa %>%
  count(snow) %>%
  arrange(desc(n))
```

For snowfall, the most commonly observed values are 0 mm and NA. This makes sense since most of the days in the year it is not snowing, and even in the winter, there isn't always snowfall. 

Next I am creating a two-panel plot showing the average max temperature in January and in July in each station across years:

```{r}
month.labs <- c("January", "July")
names(month.labs) <- as.numeric(c("1", "7"))

noaa_df %>% 
  group_by(id, year, month) %>% 
  filter(month == 1 | month == 7, na.rm = TRUE) %>% 
  summarize(
    mean_tmax = mean(tmax)
  )  %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id)) + 
    geom_point(alpha = .5) +
    geom_smooth() +
    facet_grid(. ~ month,
               labeller = labeller(month = month.labs)) +
  theme(panel.spacing = unit(2, "lines")) +
  labs(
    title = "Average Max Temperature in January and in July in NY",
    x = "Year",
    y = "Mean Maximum Temperature (C)"
  )
```

These plots show that average max temps in January are much lower than average max temps in July as is expected. There is one outlier in each graph. In January 1982 it seems there was a January that was significantly colder than the other years, while in July 1987, there was also a lower recorded temperature than usual.  


Next I am making a plot that shows tmax vs. tmin for the full dataset: 

```{r}
tmax_tmin_p = 
  noaa_df %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex()

snowfall_p = 
  noaa_df %>% 
  filter(snow > 0 & snow < 100, na.rm = TRUE) %>% 
  group_by(year) %>% 
  ggplot(aes(x = snow, y = year, group = year)) +
    geom_density_ridges() +
    labs(
      title = "Distribution of Snowfall by Year",
      x = "Snowfall (mm)",
      y = "Year"
    )

(tmax_tmin_p + snowfall_p)
```

















