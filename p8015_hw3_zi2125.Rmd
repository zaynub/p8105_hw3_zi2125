---
title: "Homework 3"
author: "Zaynub Ibrahim"
output: github_document
---

### Problem 1

```{r}
library(tidyverse)
library(p8105.datasets)
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric code. The data set shows an order number, and how long it has been since the order was placed and also shows the item that is ordered and which aisle and department it is located in. 

How many aisles, and which are most items from? 

```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

Make a plot that shows the number of items ordered in each aisle:

```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Make a table that shows most popular items in “baking ingredients”, “dog food care”, and “packaged vegetables fruits” aisles. 

```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```


### Problem 2

Read and Tidy accel_data: 

```{r}
accel_df = read_csv(file = "./data/accel_data.csv") %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "minute",
    names_prefix = "activity.",
    values_to = "activity"
  ) %>% 
  group_by(day) %>% 
  mutate(
    minute = as.numeric(minute),
    day = as.factor(day),
    activity = as.numeric(activity),
    day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")),
    weekday_or_weekend =  if_else(day %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
  )
```

This tidy accel_df dataset contains five weeks of accelerometer data collected on a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF). It has `r nrow(accel_df)` rows and `r ncol(accel_df)` and contains variables `r names(accel_df)`. 

Now I am creating a table to show total activity variable for each day.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(aggregate_activity = sum(activity)) %>% 
  knitr::kable()
```

No apparent trends stand out just from looking at this aggregate table. However, it is interesting to note that the level of activity on the last two Saturdays was significantly lower than any of the other days. 

Next, I am creating a plot that shows the 24-hour activity time courses for each day. 

```{r}
accel_df %>% 
  ggplot(aes(x = minute, y = activity)) +
  geom_point(aes(color = day)) +
  stat_smooth(method = "loess", formula = y ~ x, size = 1, se = FALSE)
```


### Problem 3 

Load the dataset: 

```{r}
data("ny_noaa")
```

This dataset contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns. 
















